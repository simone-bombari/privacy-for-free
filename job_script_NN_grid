#!/bin/bash
#
#----------------------------------
# single GPU + single CPU example
#----------------------------------
#
#SBATCH --job-name=NN-DP-JAX-13_09-layer
#SBATCH --output=logs/%A-%a_NN-DP-JAX-13_09-layer

#number of CPUs to be used
#SBATCH --ntasks=1
#
#Define the number of hours the job should run.
#Maximum runtime is limited to 10 days, ie. 240 hours
#SBATCH --time=24:00:00
#
#Define the amount of system RAM used by your job in GigaBytes
#SBATCH --mem=64G
#
#Send emails when a job starts, it is finished or it exits
#SBATCH --mail-user=sbombari@ist.ac.at
#SBATCH --mail-type=END

#SBATCH --no-requeue

## for single-CPU jobs make sure that they use a single thread
## export OMP_NUM_THREADS=1

#Define the "gpu" partition for GPU-accelerated jobs
#SBATCH --partition=gpu

#Define the number of GPUs used by your job
#SBATCH --gres=gpu:1

#Exclude the specific GPU node
#SBATCH --exclude=gpu123

#Do not export the local environment to the compute nodes
#SBATCH --export=NONE
unset SLURM_EXPORT_ENV

#load an CUDA software module
# module load python/3.9.7
# module load pytorch
module load jax-cuda/0.4.20

srun python3 ./main_NN_JAX.py --k ${SLURM_ARRAY_TASK_ID} --clipping_mode 'layer' > outputs/NN-DP-JAX-layer_${SLURM_ARRAY_TASK_ID}.txt
