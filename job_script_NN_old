#!/bin/bash
#
#----------------------------------
# single GPU + single CPU example
#----------------------------------
#
#SBATCH --job-name=rebuttal_scn_8
#SBATCH --output=logs/%A-%a_rebuttal_scn_8

#number of CPUs to be used
#SBATCH --ntasks=1
#
#Define the number of hours the job should run.
#Maximum runtime is limited to 10 days, ie. 240 hours
#SBATCH --time=6:00:00
#
#Define the amount of system RAM used by your job in GigaBytes
#SBATCH --mem=64G
#
#Send emails when a job starts, it is finished or it exits
#SBATCH --mail-user=sbombari@ist.ac.at
#SBATCH --mail-type=END
#
#Pick whether you prefer requeue or not. If you use the --requeue
#option, the requeued job script will start from the beginning,
#potentially overwriting your previous progress, so be careful.
#For some people the --requeue option might be desired if their
#application will continue from the last state.
#Do not requeue the job in the case it fails.
#SBATCH --no-requeue
#

#Define the "gpu" partition for GPU-accelerated jobs
#SBATCH --partition=gpu
#
#Define the number of GPUs used by your job
## SBATCH --gres=gpu:1
#SBATCH --gres=gpu:1080ti:1

#Do not export the local environment to the compute nodes
#SBATCH --export=NONE
unset SLURM_EXPORT_ENV

#
#
#load an CUDA software module
module load python/3.9.7
module load pytorch

hostname
#
#run your CUDA binary through SLURM's srun
python3 ./main_NN.py --i ${SLURM_ARRAY_TASK_ID} --dataset 'CIFAR-10' --net 'SCN' --save 'rebuttal_scn_width_8' > outputs/scn_8_${SLURM_ARRAY_TASK_ID}.txt
